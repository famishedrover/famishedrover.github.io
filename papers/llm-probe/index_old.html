<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Research Paper Advertisement</title>

    <style>
        body {
            font-family: 'Arial', sans-serif;
            margin: 0;
            padding: 0;
            background-color: #f4f4f4;
        }

        header {
            background-color: #333;
            color: #fff;
            text-align: center;
            padding: 1em;
        }

        .container {
            max-width: 800px;
            margin: 20px auto;
            padding: 20px;
            background-color: #fff;
            border-radius: 8px;
            box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);
        }

        h1 {
            color: #333;
        }

        video {
            width: 100%;
            height: auto;
            border-radius: 8px;
            margin-top: 10px;
        }

        img {
            width: 100%;
            height: auto;
            border-radius: 8px;
            margin-top: 10px;
        }

        pre {
            background-color: #f8f8f8;
            padding: 10px;
            border-radius: 8px;
            overflow-x: auto;
        }

        p {
            line-height: 1.6;
            color: #555;
        }
    </style>
    <meta name="google-site-verification" content="ZtYlnNZPGSiRQQa5TaPWqqqvVOnlAy9wIotvbCZ_gJY">
    <link rel="stylesheet" href="assets/bootstrap/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=ABeeZee">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Catamaran:100,200,300,400,500,600,700,800,900">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Muli">
    <link rel="stylesheet" href="assets/fonts/font-awesome.min.css">
    <link rel="stylesheet" href="assets/css/Animated-Typing-With-Blinking.css">
    <link rel="stylesheet" href="assets/css/Features-Boxed.css">
    <link rel="stylesheet" href="assets/css/Footer-with-social-media-icons.css">
    <link rel="stylesheet" href="assets/css/LinkedIn-like-Profile-Box.css">
    <link rel="stylesheet" href="assets/css/Navigation-Clean.css">
    <link rel="stylesheet" href="assets/css/Profile-Card.css">
    <link rel="stylesheet" href="assets/css/styles.css">
    <link rel="stylesheet" href="assets/css/Team-Boxed.css">   
</head>

    <header>
        <h1 style="color:white;">Theory of Mind abilities of Large Language Models in Human-Robot Interaction : An Illusion?</h1>
        <p style="color: whitesmoke;">Mudit Verma *, Siddhant Bhambri *, Subbarao Kambhampati</p>
    </header>

    <div class="container">
        <img src="teaser.png" alt="Teaser Image">
        
        <h2>Abstract</h2>
        <p>Large Language Models (LLMs) have shown exceptional generative abilities in various natural language and generation tasks. However, possible anthropomorphization and leniency towards failure cases have propelled discussions on emergent abilities of LLMs especially on Theory of Mind (ToM) abilities in Large Language Models.  While several false-belief tests exists to verify the ability to infer and maintain mental models of another entity, we study a special application of ToM abilities that has higher stakes and possibly irreversible consequences : Human Robot Interaction. In this work, we explore the task of Perceived Behavior Recognition, where a robot employs an LLM to assess the robot's generated behavior in a manner similar to human observer. We focus on four behavior types, namely - explicable, legible, predictable, and obfuscatory behavior which have been extensively used to synthesize interpretable robot behaviors. The LLMs goal is, therefore to be a human proxy to the agent, and to answer how a certain agent behavior would be perceived by the human in the loop, for example "Given a robot's behavior X, would the human observer find it explicable?". We conduct a human subject study to verify that the users are able to correctly answer such a question in the curated situations (robot setting and plan) across five domains. A first analysis of the belief test yields extremely positive results inflating ones expectations of LLMs possessing ToM abilities. We then propose and perform a suite of perturbation tests which breaks this illusion, i.e. Inconsistent Belief, Uninformative Context and Conviction Test.  The high score of LLMs on vanilla prompts showcases its potential use in HRI settings, however to possess ToM demands invariance to trivial or irrelevant perturbations in the context which LLMs lack. We report our results on GPT-4 and GPT-3.5-turbo.</p>

        <h2>Video</h2>
        To be Uploaded after conference proceedings. <a href="https://humanrobotinteraction.org/2024/schedule/">HRI 2024 Schedule</a>
        <!-- <video controls>
            <source src="research-paper-video.mp4" type="video/mp4">
            Your browser does not support the video tag.
        </video> -->

        <div class="container">
        <h2>Paper and Supplementary Materials</h2>
        <a class="btn btn-outline-info btn-sm" href="https://arxiv.org/abs/2210.09151" style="margin-left: 5px;margin-right: 5px;">Paper</a>
        </div>
        <h2>Supplementary Code</h2>
        <pre>
            <code>
                // Your code goes here
            </code>
        </pre>
    </div>

</body>
</html>
